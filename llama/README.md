# bare-bones wrappers for running llama 2 with major ML frameworks

## MLX

### prerequisites

- **mlx library:**
https://github.com/ml-explore/mlx
- **mlx-lm library**
https://github.com/ml-explore/mlx-examples/tree/main/llms
- **pytorch**
https://pytorch.org/get-started/locally/

### sample command
```sh
# prompt defaults to hello
python mlx_quickstart.py --model ~/Llama-2-7b-chat --prompt "hola"
```
